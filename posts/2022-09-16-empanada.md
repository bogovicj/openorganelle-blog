---
title: Empanada segmentations
tags: ["mitochondria", "machine learning"]
authors: ["Ryan Konrad", "Kedar Narayan", "Aubrey Weigel", "Davis Bennett"]
date: "2022-09-16"
published: True
---

# Mitochondria segmentation using Empanada and MitoNet

![Empanada logo](../assets/empanada_logo.png)![MitoNet logo](../assets/mitonet_logo.png)

From the [Narayan lab at the NCI](https://cmm.ccr.cancer.gov/volume-em/), is a library developed to efficiently train and deploy deep learning models for panotpic segmetnation of large 2D and 3D EM images coined EMPANADA. **EMPANADA** stands for **EM** **Pan**optic **An**y **D**imension **A**nnotation.
They trained a general model called _MitoNet_ to automatically segment mitochondrial instances, using empanada and a highly heterogeneous dataset of labeled mitochondria. _MitoNet_ is currently available for use in [napari](https://napari.org/) with the **empanada-napari** plugin.

Find out more about **empanada** segmentations from Kedar Narayan and Ryan Conrad on their GitHub page [here](https://volume-em.github.io/empanada).

![Mito rendering](../assets/empanada-mitos.png)

Explore these mitochondria segmentations in a FIB-SEM image volume of mouse kidney (_[jrc_mus-kidney](https://openorganelle.janelia.org/datasets/jrc_mus-kidney)_) using Neuroglancer [here](https://tinyurl.com/22whurfz). A 512 cubic micron volume rendering of this location is shown in the above image.

# Resources
- [Current version of their paper](https://www.biorxiv.org/content/10.1101/2022.03.17.484806)
- [empanada](https://github.com/volume-em/empanada.git): Source code for the empanada library. [Documentation is here](https://empanada.readthedocs.io/en/latest/index.html).
- [empanada-napari](https://github.com/volume-em/empanada-napari): Source code for the empanada-napari plugin. [Documentation is here](https://empanada.readthedocs.io/en/latest/empanada-napari.html).
- [CEM1.5M](https://www.ebi.ac.uk/empiar/EMPIAR-11035/): (Available soon at EMPIAR-11035) An unlabeled dataset of 1.5 million EM images of cells. Used for self-supervised pre-training and selecting heterogenous image data to annotate for segmentation model training.
- [CEM1.5M Pre-trained Weights](https://zenodo.org/record/6453160#.YmlzHS-cbTQ): PyTorch weights for a ResNet50 model pre-trained on CEM1.5M using the SwAV algorithm.
- [CEM-MitoLab](https://www.ebi.ac.uk/empiar/EMPIAR-11037/): (Available soon at EMPIAR-11037) A dataset of ~22,000 images containing over 135,000 individually labeled mitochondria. This is the dataset we used to train MitoNet.
- [MitoNet models](https://zenodo.org/record/6327742#.YmltqS-cbTQ): Model definition and weights as PyTorch scripted modules (includes optimized GPU and CPU versions).
- [Benchmark datasets](https://www.ebi.ac.uk/empiar/EMPIAR-10982/): Six benchmark volumes of instance segmented mitochondria from diverse volume EM datasets.
